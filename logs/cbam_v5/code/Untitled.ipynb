{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:30:54.209186Z",
     "start_time": "2019-10-17T18:30:54.199071Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import os.path as osp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# now we train a binary classifier to check whether one image is defective or not \n",
    "TRAINVAL_ANNOT = \"./input/severstal-steel-defect-detection/train.csv\"\n",
    "TRAINVAL_IMAGE_ROOT = \"./input/severstal-steel-defect-detection/train_images/\"\n",
    "\n",
    "sample_submission_path = './input/severstal-steel-defect-detection/sample_submission.csv'\n",
    "train_df_path = './input/severstal-steel-defect-detection/train.csv'\n",
    "data_folder = \"./input/severstal-steel-defect-detection/\"\n",
    "test_data_folder = \"./input/severstal-steel-defect-detection/test_images\"\n",
    "FOLDS_ids = './input/folds.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:30:55.509652Z",
     "start_time": "2019-10-17T18:30:55.438062Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channel, reduction_ratio=16, num_layers=1):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_activation = gate_activation\n",
    "        self.gate_c = nn.Sequential()\n",
    "        self.gate_c.add_module( 'flatten', Flatten() )\n",
    "        gate_channels = [gate_channel]\n",
    "        gate_channels += [gate_channel // reduction_ratio] * num_layers\n",
    "        gate_channels += [gate_channel]\n",
    "        for i in range( len(gate_channels) - 2 ):\n",
    "            self.gate_c.add_module( 'gate_c_fc_%d'%i, nn.Linear(gate_channels[i], gate_channels[i+1]) )\n",
    "            self.gate_c.add_module( 'gate_c_bn_%d'%(i+1), nn.BatchNorm1d(gate_channels[i+1]) )\n",
    "            self.gate_c.add_module( 'gate_c_relu_%d'%(i+1), nn.ReLU() )\n",
    "        self.gate_c.add_module( 'gate_c_fc_final', nn.Linear(gate_channels[-2], gate_channels[-1]) )\n",
    "    def forward(self, in_tensor):\n",
    "        avg_pool = F.avg_pool2d( in_tensor, in_tensor.size(2), stride=in_tensor.size(2) )\n",
    "        return self.gate_c( avg_pool ).unsqueeze(2).unsqueeze(3).expand_as(in_tensor)\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self, gate_channel, reduction_ratio=16, dilation_conv_num=2, dilation_val=4):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        self.gate_s = nn.Sequential()\n",
    "        self.gate_s.add_module( 'gate_s_conv_reduce0', nn.Conv2d(gate_channel, gate_channel//reduction_ratio, kernel_size=1))\n",
    "        self.gate_s.add_module( 'gate_s_bn_reduce0',\tnn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
    "        self.gate_s.add_module( 'gate_s_relu_reduce0',nn.ReLU() )\n",
    "        for i in range( dilation_conv_num ):\n",
    "            self.gate_s.add_module( 'gate_s_conv_di_%d'%i, nn.Conv2d(gate_channel//reduction_ratio, gate_channel//reduction_ratio, kernel_size=3, \\\n",
    "\t\t\t\t\t\tpadding=dilation_val, dilation=dilation_val) )\n",
    "            self.gate_s.add_module( 'gate_s_bn_di_%d'%i, nn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
    "            self.gate_s.add_module( 'gate_s_relu_di_%d'%i, nn.ReLU() )\n",
    "        self.gate_s.add_module( 'gate_s_conv_final', nn.Conv2d(gate_channel//reduction_ratio, 1, kernel_size=1) )\n",
    "    def forward(self, in_tensor):\n",
    "        return self.gate_s( in_tensor ).expand_as(in_tensor)\n",
    "class BAM(nn.Module):\n",
    "    def __init__(self, gate_channel):\n",
    "        super(BAM, self).__init__()\n",
    "        self.channel_att = ChannelGate(gate_channel)\n",
    "        self.spatial_att = SpatialGate(gate_channel)\n",
    "    def forward(self,in_tensor):\n",
    "        att = 1 + F.sigmoid( self.channel_att(in_tensor) * self.spatial_att(in_tensor) )\n",
    "        return att * in_tensor\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes * 4, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers,  network_type, num_classes, att_type=None):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.network_type = network_type\n",
    "        # different model config between ImageNet and CIFAR \n",
    "        if network_type == \"ImageNet\":\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            self.avgpool = nn.AvgPool2d(7)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if att_type=='BAM':\n",
    "            self.bam1 = BAM(64*block.expansion)\n",
    "            self.bam2 = BAM(128*block.expansion)\n",
    "            self.bam3 = BAM(256*block.expansion)\n",
    "        else:\n",
    "            self.bam1, self.bam2, self.bam3 = None, None, None\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], att_type=att_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_type=att_type)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_type=att_type)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, att_type=att_type)\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        init.kaiming_normal(self.fc.weight)\n",
    "        for key in self.state_dict():\n",
    "            if key.split('.')[-1]==\"weight\":\n",
    "                if \"conv\" in key:\n",
    "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
    "                if \"bn\" in key:\n",
    "                    if \"SpatialGate\" in key:\n",
    "                        self.state_dict()[key][...] = 0\n",
    "                    else:\n",
    "                        self.state_dict()[key][...] = 1\n",
    "            elif key.split(\".\")[-1]=='bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, att_type=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=att_type=='CBAM'))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, use_cbam=att_type=='CBAM'))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        if not self.bam1 is None:\n",
    "            x = self.bam1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        if not self.bam2 is None:\n",
    "            x = self.bam2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        if not self.bam3 is None:\n",
    "            x = self.bam3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.avgpool(x)\n",
    "        else:\n",
    "            x = F.avg_pool2d(x, 4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def ResidualNet(network_type, depth, num_classes, att_type):\n",
    "\n",
    "    assert network_type in [\"ImageNet\", \"CIFAR10\", \"CIFAR100\"], \"network type should be ImageNet or CIFAR10 / CIFAR100\"\n",
    "    assert depth in [18, 34, 50, 101], 'network depth should be 18, 34, 50 or 101'\n",
    "\n",
    "    if depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:43:49.679987Z",
     "start_time": "2019-10-17T18:43:41.784893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11311/1257 images for train/val.\n",
      "Epoch: 0 | Phase: val\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4e875070e542ebadffa28b887058c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 0 mins and 7 secs, loss: 0.625, acc: 73.548%\n",
      "****** Find new optimal model, saving to disk ******\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './weights/model_resne50.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a9de144177e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resnet50\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-a9de144177e0>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-a9de144177e0>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    188\u001b[0m         }\n\u001b[1;32m    189\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"****** Find new optimal model, saving to disk ******\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './weights/model_resne50.pth'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "def get_annot(annot_path):\n",
    "    trainval_annot = pd.read_csv(TRAINVAL_ANNOT)\n",
    "    trainval_annot['ImageId'] = trainval_annot['ImageId_ClassId'].apply(lambda x: x.split(\"_\")[0])\n",
    "    trainval_annot['ClassId'] = trainval_annot['ImageId_ClassId'].apply(lambda x: x.split(\"_\")[1])\n",
    "    trainval_annot['HasMask'] = trainval_annot['EncodedPixels'].notnull().astype('int')\n",
    "    trainval_annot = trainval_annot[['ImageId', 'ClassId', 'HasMask']].groupby(['ImageId', 'ClassId']).max().unstack().sort_index(axis=1).reset_index()\n",
    "    trainval_annot.columns = ['ImageId', '1', '2', '3', '4']\n",
    "    kfold = KFold(10, shuffle=True,\n",
    "                          random_state=69)  # StratifiedKFold(total_folds, shuffle=True, random_state=69)\n",
    "    train_idx, val_idx = list(kfold.split(trainval_annot))[0]  # , df[\"defects\"]\n",
    "    train_annot, val_annot = trainval_annot.iloc[train_idx], trainval_annot.iloc[val_idx]\n",
    "    #train_annot, val_annot = train_test_split(trainval_annot, test_size=0.10)\n",
    "    print(\"{}/{} images for train/val.\".format(len(train_annot), len(val_annot)))\n",
    "    return {\"train\": train_annot, \"val\": val_annot}\n",
    "\n",
    "def prev_get_transform(phase):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "          list_transforms.extend(\n",
    "              [RandomCrop(256, 1024, p=1),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                RandomBrightnessContrast(p=0.1, brightness_limit=0.1, contrast_limit=0.1)\n",
    "                ])\n",
    "\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1),\n",
    "            ToTensor()\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def get_transform(phase):\n",
    "    list_transform = []\n",
    "    if phase == 'train':\n",
    "        list_transform.extend([\n",
    "            transforms.Resize((256, 256+128)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        list_transform.extend([\n",
    "            transforms.Resize((256, 256+128)),\n",
    "            # transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    return transforms.Compose(list_transform)\n",
    "\n",
    "def criterion(logit, truth, weight=None):\n",
    "    batch_size,num_class = logit.shape\n",
    "    assert(logit.shape==truth.shape)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(logit, truth, reduction='none')\n",
    "\n",
    "    if weight is None:\n",
    "        loss = loss.mean()\n",
    "\n",
    "    else:\n",
    "        pos = (truth>0.5).float()\n",
    "        neg = (truth<0.5).float()\n",
    "        pos_sum = pos.sum().item() + 1e-12\n",
    "        neg_sum = neg.sum().item() + 1e-12\n",
    "        loss = (weight[1]*pos*loss/pos_sum + weight[0]*neg*loss/neg_sum).sum()\n",
    "        #raise NotImplementedError\n",
    "\n",
    "    return loss\n",
    "\n",
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, annot, image_folder, phase):\n",
    "        self.annot = annot\n",
    "        self.image_folder = image_folder\n",
    "        self.phase = phase\n",
    "        self.transform = get_transform(phase)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.annot.iloc[index, :]\n",
    "        image_path = osp.join(self.image_folder, row['ImageId'])\n",
    "        target = torch.tensor([row['1'], row['2'], row['3'], row['4']], dtype=torch.float)\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        return image, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annot)\n",
    "    \n",
    "    \n",
    "def get_dataloader(annot, image_folder, phase, batch_size=16, num_workers=4):\n",
    "    dataset = SteelDataset(annot, image_folder, phase)\n",
    "    return DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "def get_model(model_name):\n",
    "    model = ResidualNet('ImageNet', 50, 4, 'cbam')\n",
    "    # model = models.__dict__[model_name]()\n",
    "    # if model_name.startswith(\"resnet\"):\n",
    "    #     in_features = model.fc.in_features\n",
    "    #     model.fc = nn.Linear(in_features, 4)\n",
    "    # else:\n",
    "    #     raise KeyError(\"Only support resnet!\")\n",
    "    return model\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,  model_name=\"resnet34\", pretrained=False, epochs=1):\n",
    "        self.lr = 5e-4\n",
    "        self.threshold = 0.5\n",
    "        self.best_acc = 0.0\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        self.model_path = './weights/model_resne50.pth'\n",
    "        self.pretrained = pretrained\n",
    "        self.pretrained_model_path = osp.join(\"../input/severstal-binary-classifier/\", self.model_path)\n",
    "        self.num_epochs = epochs\n",
    "        self.annot_path = TRAINVAL_ANNOT\n",
    "        self.image_folder = TRAINVAL_IMAGE_ROOT\n",
    "        self.phases = [ 'val'] #'train',\n",
    "        self.batch_sizes = {'train': 16, 'val': 16}#\n",
    "        self.model = get_model(model_name).to(self.device)\n",
    "        # self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9, weight_decay=5e-4)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.5) #ReduceLROnPlateau(self.optimizer, factor=0.9, mode=\"min\", patience=3, verbose=True)\n",
    "        self.criterion = criterion#nn.CrossEntropyLoss()\n",
    "        self.annots = get_annot(self.annot_path)\n",
    "        self.dataloaders = {phase: get_dataloader(self.annots[phase], self.image_folder, \n",
    "                                phase, self.batch_sizes[phase]) for phase in self.phases}\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.accuracies = {phase: [] for phase in self.phases}\n",
    "        \n",
    "        self.targets = []\n",
    "        self.preds = []\n",
    "    def forward(self, inputs, targets):   \n",
    "        inputs = inputs.to(self.device, dtype=torch.float)\n",
    "        targets = targets.to(self.device, dtype=torch.float)\n",
    "        outputs = self.model(inputs)\n",
    "        #targets = targets.unsqueeze(1).float()\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        return loss, outputs\n",
    "        \n",
    "    def iterate(self, epoch, phase):\n",
    "        start = time.time()\n",
    "        print(\"Epoch: {} | Phase: {}\".format(epoch, phase))\n",
    "        self.model.train(phase == 'train')\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        self.optimizer.zero_grad()\n",
    "        tk = tqdm(dataloader, total=len(dataloader))\n",
    "        torch.set_grad_enabled(phase == 'train')\n",
    "        self.targets = []\n",
    "        self.preds = []\n",
    "        for idx, batch in enumerate(tk):\n",
    "            inputs, targets = batch\n",
    "            loss, outputs = self.forward(inputs, targets)\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            preds = (torch.sigmoid(outputs) > self.threshold).reshape_as(targets).int().cpu()\n",
    "            self.preds.append(preds)\n",
    "            self.preds.append(targets.int())\n",
    "            running_corrects += (preds == targets.int()).sum().item()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            tk.set_postfix(loss=running_loss / ((idx+1) * self.batch_sizes[phase]), running_corrects=running_corrects/(4*self.batch_sizes[phase]*(idx+1)))\n",
    "            tk.update()\n",
    "        torch.set_grad_enabled(phase == 'train')\n",
    "        \n",
    "        dataset_size = len(dataloader.dataset)\n",
    "        running_loss /= dataset_size\n",
    "        running_acc = running_corrects/ (dataset_size*4)\n",
    "        self.losses[phase].append(running_loss)\n",
    "        self.accuracies[phase].append(running_acc)\n",
    "        end  = time.time()\n",
    "        time_elapsed = int(end - start)\n",
    "        print(\"Finished in {} mins and {} secs, loss: {:.3f}, acc: {:.3f}%\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60, running_loss, running_acc * 100))\n",
    "        return running_acc\n",
    "        \n",
    "    def save_model(self, epoch):\n",
    "        state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"best_acc\": self.best_acc, \n",
    "            \"state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict()\n",
    "        }\n",
    "        print(\"****** Find new optimal model, saving to disk ******\")\n",
    "        torch.save(state, self.model_path)\n",
    "        return \n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"Training finished. Best val acc: {:.3f}%\".format(self.best_acc*100))\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "        len_x = len(self.losses['train'])\n",
    "        ax1.plot(range(len_x), self.losses['train'], label=\"train loss\")\n",
    "        ax1.plot(range(len_x), self.losses['val'], label=\"val loss\")\n",
    "        #ax1.title(\"loss curve\");   ax1.xlabel(\"epoch\");   ax1.ylabel(\"loss\")\n",
    "        ax2.plot(range(len_x), self.accuracies['train'], label='train acc')\n",
    "        ax2.plot(range(len_x), self.accuracies['val'], label='val acc')\n",
    "        #ax2.title(\"accuracy curve\");  ax2.xlabel(\"epoch\");  ax2.ylabel(\"accuracy\")\n",
    "        plt.show()\n",
    "    \n",
    "    def start(self):\n",
    "        resume_epoch = 0\n",
    "        if self.pretrained or osp.exists(self.model_path):\n",
    "            state = torch.load(self.pretrained_model_path) if self.pretrained else torch.load(self.model_path)\n",
    "            resume_epoch = state['epoch'] + 1\n",
    "            self.best_acc = state['best_acc']\n",
    "            self.optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "            self.model.load_state_dict(state['state_dict'])\n",
    "            print(\"Load checkpoint from {}, resume training from {} epoch with best acc {}%\".format(\n",
    "                    self.model_path, resume_epoch, self.best_acc * 100))\n",
    "            \n",
    "        for epoch in range(resume_epoch, self.num_epochs):\n",
    "            if 'train' in self.phases:\n",
    "                train_acc = self.iterate(epoch, 'train')\n",
    "                self.scheduler.step()\n",
    "            val_acc = self.iterate(epoch, 'val')\n",
    "            if val_acc > self.best_acc:\n",
    "                self.best_acc = val_acc\n",
    "                self.save_model(epoch)\n",
    "        self.summary()\n",
    "%matplotlib inline\n",
    "trainer = Trainer(\"resnet50\", pretrained=False, epochs = 1)\n",
    "trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:35:05.686057Z",
     "start_time": "2019-10-17T18:35:05.267161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = ResidualNet('ImageNet', 34, 4, 'cbam')\n",
    "    # model = models.__dict__[model_name]()\n",
    "    # if model_name.startswith(\"resnet\"):\n",
    "    #     in_features = model.fc.in_features\n",
    "    #     model.fc = nn.Linear(in_features, 4)\n",
    "    # else:\n",
    "    #     raise KeyError(\"Only support resnet!\")\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "state = torch.load('/home/dex/Downloads/model_resnet34.pth')\n",
    "model.load_state_dict(state['state_dict'])\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:39:51.783713Z",
     "start_time": "2019-10-17T18:39:51.761664Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multilabel_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ba96dc47561e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbest_fsores_th\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multilabel_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "def \n",
    "num_classes =4\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "best_th = 0\n",
    "\n",
    "best_fsores = {c:0 for c in range(4)}\n",
    "best_fsores_th = {}\n",
    "for th in np.linspace(0, 1, 41):\n",
    "    cm = multilabel_confusion_matrix(targets, outputs>th, labels=range(num_classes))\n",
    "    for c in range(num_classes):\n",
    "\n",
    "        tn, fp, fn, tp = cm[c].ravel()\n",
    "\n",
    "        if (tp + fp) == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = tp/(tp+fp)\n",
    "\n",
    "        if (tp+fn) == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = tp/(tp+fn)\n",
    "\n",
    "        if precision == 0 or recall == 0:\n",
    "            fscore = 0\n",
    "        else:\n",
    "            fscore = 2 * (precision*recall/(precision+recall))\n",
    "        if best_fsores[c] < fscore:\n",
    "            best_fsores_th[c] = th\n",
    "            state.metrics.epoch_values[state.loader_name][str(c)+'_precision_best'] = precision\n",
    "            state.metrics.epoch_values[state.loader_name][str(c)+'_recall_best'] = recall\n",
    "            state.metrics.epoch_values[state.loader_name][str(c)+'_fscore_best'] = fscore\n",
    "            state.metrics.epoch_values[state.loader_name][str(c)+'_fscore_best_th'] = th\n",
    "            best_fsores[c] = fscore\n",
    "\n",
    "\n",
    "\n",
    "state.metrics.epoch_values[state.loader_name]['fscore_macro_best'] = np.mean([best_fsores[i] for i in best_fsores])      \n",
    "cm = multilabel_confusion_matrix(targets, outputs>0.5, labels=range(num_classes))\n",
    "for c in range(num_classes):\n",
    "\n",
    "    tn, fp, fn, tp = cm[c].ravel()\n",
    "    if (tp + fp) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "\n",
    "    if (tp+fn) == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = tp/(tp+fn)\n",
    "    if precision == 0 or recall == 0:\n",
    "        fscore = 0\n",
    "    else:\n",
    "        fscore = 2 * (precision*recall/(precision+recall))\n",
    "    state.metrics.epoch_values[state.loader_name][str(c)+'_precision_05'] = precision\n",
    "    state.metrics.epoch_values[state.loader_name][str(c)+'_recall_05'] = recall\n",
    "    state.metrics.epoch_values[state.loader_name][str(c)+'_fscore_05'] = fscore\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
