{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjrz4a0b5zMw"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:24.673711Z",
     "start_time": "2019-10-17T21:14:23.610962Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DCl3bKkU5zMx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch.transforms import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:25.378046Z",
     "start_time": "2019-10-17T21:14:25.349448Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:25.852656Z",
     "start_time": "2019-10-17T21:14:25.827267Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GY1yfQ365zM5"
   },
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ru_JjA3u5zM8"
   },
   "source": [
    "### Dataloader\n",
    "\n",
    "Writing helper class for data extraction, tranformation and preprocessing  \n",
    "https://pytorch.org/docs/stable/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:27.503934Z",
     "start_time": "2019-10-17T21:14:27.482382Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "okIYiGn_5zM9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:28.181658Z",
     "start_time": "2019-10-17T21:14:28.147936Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_mask2(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((256, 1600, 5), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx+1] = mask.reshape(256, 1600, order='F')\n",
    "    masks[:,:,0] = 1 - 1*(masks.sum(axis=2)>0)\n",
    "    return fname, masks\n",
    "\n",
    "\n",
    "\n",
    "class Dataset(BaseDataset):\n",
    "\n",
    "    CLASSES = ['1', '2', '3', '4']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            df, data_folder, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "\n",
    "        self.fnames = self.df.index.tolist()\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_id, mask = make_mask2(idx, self.df)\n",
    "        \n",
    "        image_path = os.path.join(self.root, image_id)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        \n",
    "        targets = 1*(mask.sum(axis=(1,2))[1:]>0)\n",
    "#         print(targets)\n",
    "        targets = torch.tensor(targets).float()\n",
    "            \n",
    "        return {'features': image, 'masks': mask, 'targets': targets}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:30.481488Z",
     "start_time": "2019-10-17T21:14:30.459443Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGES_FULL= './input/severstal-steel-defect-detection/train_images/'\n",
    "IMAGES_OUT= './input/images_crop256x256/'\n",
    "MASKS_OUT = './input/masks_crop256x256/'\n",
    "IMAGES_N_OUT = './input/neg_images__crop256x256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:31.370567Z",
     "start_time": "2019-10-17T21:14:31.050839Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "xwDKSwsC5zNA",
    "outputId": "7e62a83b-a30a-4de4-faa6-66d51d8fed9a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./input/severstal-steel-defect-detection/train.csv')\n",
    "\n",
    "df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "df['ClassId'] = df['ClassId'].astype(int)\n",
    "df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "df['defects'] = df.count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:32.414378Z",
     "start_time": "2019-10-17T21:14:32.388037Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "xwDKSwsC5zNA",
    "outputId": "7e62a83b-a30a-4de4-faa6-66d51d8fed9a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_folds = 10\n",
    "kfold = KFold(total_folds, shuffle=True,random_state=69)\n",
    "\n",
    "train_idx, val_idx = list(kfold.split(df))[0]\n",
    "train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:33.565972Z",
     "start_time": "2019-10-17T21:14:33.514776Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "for j in os.listdir('./input/severstal-steel-defect-detection/test_images'):\n",
    "    for i in range(1,5):\n",
    "        names.append(j+'_{}'.format(i))\n",
    "test_df = pd.DataFrame(names)\n",
    "test_df.columns = ['ImageId_ClassId']\n",
    "test_df['EncodedPixels'] = np.nan\n",
    "\n",
    "test_df['ImageId'], test_df['ClassId'] = zip(*test_df['ImageId_ClassId'].str.split('_'))\n",
    "test_df['ClassId'] = test_df['ClassId'].astype(int)\n",
    "test_df = test_df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "test_df['defects'] = test_df.count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:35.367553Z",
     "start_time": "2019-10-17T21:14:35.346965Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "f979TGC25zNH"
   },
   "outputs": [],
   "source": [
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:35.926299Z",
     "start_time": "2019-10-17T21:14:35.900980Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aQJ4fPYI5zNJ"
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.3),\n",
    "\n",
    "        albu.RandomBrightness(p=0.1, limit=1),\n",
    "        albu.RandomContrast(p=0.1, limit=1),\n",
    "#         albu.CropNonEmptyMaskIfExists(256,512,ignore_channels=[0], p=1., always_apply=True),\n",
    "\n",
    "#         albu.IAAAdditiveGaussianNoise(p=0.2),\n",
    "\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyTjvl_x5zNN"
   },
   "source": [
    "## Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:38.543619Z",
     "start_time": "2019-10-17T21:14:37.656746Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1RhasOVZ5zNO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "def get_model(model_name: str, num_classes: int, pretrained: str = \"imagenet\"):\n",
    "    model_fn = pretrainedmodels.__dict__[model_name]\n",
    "    model = model_fn(num_classes=1000, pretrained=pretrained)\n",
    "    \n",
    "    dim_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(dim_feats, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:39.945267Z",
     "start_time": "2019-10-17T21:14:39.923391Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Sf3rKNhl5zNP"
   },
   "outputs": [],
   "source": [
    "model_name = \"resnet34\"\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:40.727287Z",
     "start_time": "2019-10-17T21:14:40.706726Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tx5qw79T5zNR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:43.162926Z",
     "start_time": "2019-10-17T21:14:42.475894Z"
    }
   },
   "outputs": [],
   "source": [
    "from model_resnet import ResidualNet\n",
    "\n",
    "model = ResidualNet( 'ImageNet', 50, 1000, 'CBAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:46.272666Z",
     "start_time": "2019-10-17T21:14:44.260566Z"
    }
   },
   "outputs": [],
   "source": [
    "state = torch.load(\"/home/dex/Downloads/cbam/cbam/RESNET50_CBAM_new_name_wrap.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:49.341679Z",
     "start_time": "2019-10-17T21:14:49.324667Z"
    }
   },
   "outputs": [],
   "source": [
    "new_state_dict = {}\n",
    "for j in state['state_dict'].keys():\n",
    "    j_ = j[7:]\n",
    "    new_state_dict[j_] = state['state_dict'][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:14:55.215806Z",
     "start_time": "2019-10-17T21:14:55.152920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:17:37.407143Z",
     "start_time": "2019-10-17T21:17:37.377404Z"
    }
   },
   "outputs": [],
   "source": [
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "#                       nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                      nn.Dropout(p=0.5),\n",
    "#                       nn.Linear(in_features=2048, out_features=512, bias=True),\n",
    "#                       nn.ELU(True),\n",
    "#                       nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "#                       nn.Dropout(p=0.4),\n",
    "                      nn.Linear(in_features=2048, out_features=4, bias=True)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:06.523136Z",
     "start_time": "2019-10-17T21:15:06.502502Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES = ['0','1','2','3','4']\n",
    "train_dataset = Dataset(\n",
    "    train_df, \"../../train_images/\", \n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    val_df, \"../../train_images/\", \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:12.309959Z",
     "start_time": "2019-10-17T21:15:12.217195Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['classes'] = train_df[1].isnull().astype(str)+'&'+train_df[2].isnull().astype(str)+'&'+train_df[3].isnull().astype(str)+'&'+train_df[4].isnull().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:18.489961Z",
     "start_time": "2019-10-17T21:15:18.150297Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.loc[train_df['classes']=='False&False&True&True', 'classes'] = 'True&False&True&True'\n",
    "train_df.loc[train_df['classes']=='True&True&False&False', 'classes'] = 'True&True&True&False'\n",
    "train_df.loc[train_df['classes']=='False&True&False&True', 'classes'] = 'False&True&True&True'\n",
    "train_df.loc[train_df['classes']=='True&False&False&True', 'classes'] = 'True&False&True&True'\n",
    "train_df.loc[train_df['classes']=='False&False&False&True', 'classes'] = 'True&False&True&True'\n",
    "train_df.loc[train_df['classes']=='True&False&True&False', 'classes'] = 'True&False&True&True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:24.155894Z",
     "start_time": "2019-10-17T21:15:24.135576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True&True&True&True     5330\n",
       "True&True&False&True    4276\n",
       "False&True&True&True     761\n",
       "True&True&True&False     725\n",
       "True&False&True&True     219\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['classes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:29.740073Z",
     "start_time": "2019-10-17T21:15:29.721506Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:35.702778Z",
     "start_time": "2019-10-17T21:15:35.400453Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "\n",
    "labels, _ = pd.factorize(train_df.classes)\n",
    "sampler = BalanceClassSampler(labels, mode=\"downsampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:41.617113Z",
     "start_time": "2019-10-17T21:15:41.594009Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "WSwo7d9A5zNV",
    "outputId": "4f155340-8e17-428f-d26f-413924b9a8ce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    train_df, \"../../train_images/\", \n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    val_df, \"../../train_images/\", \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, num_workers=4, sampler=sampler)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFtDYPk68H7Z"
   },
   "source": [
    "# Catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = torch.load(\"./logs/segmentation_notebook/checkpoints/last.pth\")\n",
    "# model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPsESkA194PH"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:47.897110Z",
     "start_time": "2019-10-17T21:15:47.299015Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "AAQdydOw7A8n",
    "outputId": "8e095b7d-c0bc-4e48-a90d-2413ab3e318f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.dl.callbacks import DiceCallback\n",
    "\n",
    "\n",
    "# folder for all the experiment logs\n",
    "logdir = \"./logs/cbam_v5/\"\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "loaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"valid\": valid_loader\n",
    "}\n",
    "\n",
    "# model, criterion, optimizer\n",
    "# model = # already defined\n",
    "\n",
    "criterion = {\n",
    "    \"bce\": nn.BCEWithLogitsLoss(),\n",
    "}\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), 0.1,\n",
    "#                             momentum=0.9,\n",
    "#                             weight_decay=1e-4)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters(), 'lr': 3e-4},])\n",
    "\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': model.decoder.parameters(), 'lr': 3e-4}, \n",
    "    \n",
    "#     # decrease lr for encoder in order not to permute \n",
    "#     # pre-trained weights with large gradients on training start\n",
    "#     {'params': model.encoder.parameters(), 'lr': 3e-5},  \n",
    "# ])\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.9, patience=3)\n",
    "\n",
    "# model runner\n",
    "runner = SupervisedRunner(input_target_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:15:53.821872Z",
     "start_time": "2019-10-17T21:15:53.792915Z"
    }
   },
   "outputs": [],
   "source": [
    "from catalyst.dl.callbacks import InferCallback, CheckpointCallback, CriterionCallback, CriterionAggregatorCallback\n",
    "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback, F1ScoreCallback\n",
    "from new_metrics import MacroF1Callback, ConfusionMatrixCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-17T21:18:06.814Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    callbacks=[               \n",
    "        \n",
    "               CriterionCallback(prefix=\"loss_bce\",input_key='targets',\n",
    "                     criterion_key='bce', multiplier=1.),\n",
    "\n",
    "               CriterionAggregatorCallback(prefix=\"loss\",loss_keys=[ 'loss_bce']),\n",
    "        \n",
    "        \n",
    "               CheckpointCallback(save_n_best=3),\n",
    "        \n",
    "               MacroF1Callback(),\n",
    "        \n",
    "               ConfusionMatrixCallback()],\n",
    "               \n",
    "\n",
    "    optimizer=optimizer,\n",
    "    main_metric='macro_f1',\n",
    "    minimize_metric=False,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "#     fp16={\"opt_level\": \"O1\"},\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(0.0001,0, atol=10**-4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "79/200 * Epoch 79 (valid): 0_fscore_05=0.8584 | 0_fscore_best=0.8981 | 0_fscore_best_th=0.6750 | 0_precision_05=0.7951 | 0_precision_best=0.8661 | 0_recall_05=0.9327 | 0_recall_best=0.9327 | 1_fscore_05=0.8679 | 1_fscore_best=0.8846 | 1_fscore_best_th=0.5750 | 1_precision_05=0.9200 | 1_precision_best=0.9583 | 1_recall_05=0.8214 | 1_recall_best=0.8214 | 2_fscore_05=0.9244 | 2_fscore_best=0.9251 | 2_fscore_best_th=0.4250 | 2_precision_05=0.9427 | 2_precision_best=0.9341 | 2_recall_05=0.9068 | 2_recall_best=0.9163 | 3_fscore_05=0.9530 | 3_fscore_best=0.9655 | 3_fscore_best_th=0.9750 | 3_precision_05=0.9595 | 3_precision_best=1.0000 | 3_recall_05=0.9467 | 3_recall_best=0.9333 | _base/lr=4.503e-05 | _base/momentum=0.9000 | _timers/_fps=185.9150 | _timers/batch_time=0.0464 | _timers/data_time=0.0345 | _timers/model_time=0.0118 | fscore_macro_best=0.9184 | loss=0.0800 | loss_bce=0.0800 | macro_f1=0.9009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cars segmentation (camvid).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
