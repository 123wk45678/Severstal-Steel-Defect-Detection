{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet Inference kernel\n",
    "\n",
    "This kernel is an inference kernel of my [UNet starter kernel](https://www.kaggle.com/rishabhiitbhu/unet-starter-kernel-pytorch-lb-0-888). \n",
    "Don't forget to add the `model.pth` file generated from the starter kernel as dataset to predict on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from pretrainedmodels==0.7.4) (1.2.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from pretrainedmodels==0.7.4) (0.4.0a0+6b959ee)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.6/site-packages (from pretrainedmodels==0.7.4) (2.3.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from pretrainedmodels==0.7.4) (4.36.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch->pretrainedmodels==0.7.4) (1.16.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision->pretrainedmodels==0.7.4) (1.12.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision->pretrainedmodels==0.7.4) (5.4.1)\r\n",
      "Building wheels for collected packages: pretrainedmodels\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60963 sha256=be2d5a91efacf4b379a116ea4e733c6ba22ef89ef00fbce9117ecabedea045df\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/52/1a/2a/9e4582032d4e47d36ff06371d5579b3a6622985bdf37ee4b20\r\n",
      "Successfully built pretrainedmodels\r\n",
      "Installing collected packages: pretrainedmodels\r\n",
      "Successfully installed pretrainedmodels-0.7.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# What this is doing? please refer to my above linked kernel\n",
    "#!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null\n",
    "package_path = '../input/unetmodelscript/'\n",
    "import sys\n",
    "sys.path.append(package_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch import ToTensor\n",
    "import torch.utils.data as data\n",
    "from model import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    '''Dataset for test prediction'''\n",
    "    def __init__(self, root, df, mean, std,TTA=False):\n",
    "        self.root = root\n",
    "        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "        self.fnames = df['ImageId'].unique().tolist()\n",
    "        self.num_samples = len(self.fnames)\n",
    "        if TTA==True:\n",
    "            self.transform = Compose(\n",
    "                [\n",
    "                    HorizontalFlip(),\n",
    "                    Normalize(mean=mean,std=std,p=1),\n",
    "                    ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = Compose(\n",
    "                [\n",
    "                    Normalize(mean=mean, std=std, p=1),\n",
    "                    ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname)\n",
    "        image = cv2.imread(path)\n",
    "        images = self.transform(image=image)[\"image\"]\n",
    "        return fname, images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability, threshold, min_size):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((256, 1600), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../input/infer_test/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/infer_test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\n",
    "test_data_folder = \"../input/severstal-steel-defect-detection/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold 0.5\n"
     ]
    }
   ],
   "source": [
    "# initialize test dataloader\n",
    "best_threshold = 0.5\n",
    "num_workers = 2\n",
    "batch_size = 1\n",
    "print('best_threshold', best_threshold)\n",
    "min_size = 3500\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "df = pd.read_csv(sample_submission_path)\n",
    "testset = DataLoader(\n",
    "    TestDataset(test_data_folder, df, mean, std),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "testset_TTA = DataLoader(\n",
    "    TestDataset(test_data_folder,df,mean,std,TTA=True),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_fold_2.pth',\n",
       " 'model_fold_1.pth',\n",
       " 'model_fold_4.pth',\n",
       " 'model_fold_3.pth',\n",
       " 'model_fold_0.pth']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('../input/infer-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize mode and load trained weights\n",
    "# predictions = []\n",
    "# model_name = \"resnet18\"\n",
    "# models = []\n",
    "# for i in range(4):\n",
    "#     #ckpt_path = \"../input/uresnet/u-resnet18_fold_{}.pth\".format(i)\n",
    "#     ckpt_path = \"../input/ures184fold/u-resnet18_fold_{}.pth\".format(i)\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     model = Unet(encoder_name=\"resnet18\",classes=4,activation=None, encoder_weights=None)\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "#     state = torch.load(ckpt_path,map_location=lambda storage,loc:storage)\n",
    "#     #model.load_state_dict(state[\"state_dict\"])\n",
    "#     from collections import OrderedDict\n",
    "#     new_state_dict = OrderedDict()\n",
    "\n",
    "#     for k, v in state['state_dict'].items():\n",
    "#         if k in model.state_dict():\n",
    "#             new_state_dict[k]=v\n",
    "\n",
    "#     model.load_state_dict(new_state_dict)\n",
    "#     models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/infer-test/model_fold_2.pth\n",
      "../input/infer-test/model_fold_1.pth\n",
      "../input/infer-test/model_fold_4.pth\n",
      "../input/infer-test/model_fold_3.pth\n",
      "../input/infer-test/model_fold_0.pth\n"
     ]
    }
   ],
   "source": [
    "# Initialize mode and load trained weights\n",
    "from collections import OrderedDict\n",
    "\n",
    "predictions = []\n",
    "model_name = \"resnet18\"\n",
    "models = []\n",
    "for ckpt_path in os.listdir('../input/infer-test'):\n",
    "    #ckpt_path = \"../input/uresnet/u-resnet18_fold_{}.pth\".format(i)\n",
    "    #ckpt_path = \"../input/ures184fold/u-resnet18_fold_{}.pth\".format(i)\n",
    "    ckpt_path = os.path.join('../input/infer-test', ckpt_path)\n",
    "    print(ckpt_path)\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = Unet(encoder_name=\"resnet18\",classes=4,activation=None, encoder_weights=None)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    state = torch.load(ckpt_path,map_location=lambda storage,loc:storage)\n",
    "    #model.load_state_dict(state[\"state_dict\"])\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state['state_dict'].items():\n",
    "        if k in model.state_dict():\n",
    "            new_state_dict[k]=v\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1801it [05:44,  5.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# start prediction\n",
    "predictions = []\n",
    "for i, (batch,batch_TTA) in enumerate(tqdm(zip(testset,testset_TTA))):\n",
    "    fnames, images = batch\n",
    "    fnames, images_TTA = batch_TTA\n",
    "    batch_preds = 0\n",
    "    for model in models:\n",
    "        pred = torch.sigmoid(model(images.to(device))).detach().cpu().numpy()\n",
    "        pred_TTA = torch.sigmoid(model(images_TTA.to(device))).detach().cpu().numpy()\n",
    "        batch_preds += (pred+pred_TTA[:,:,:,::-1])/2\n",
    "        batch_preds+=pred\n",
    "    batch_preds/= len(models)\n",
    "    #batch_preds = batch_preds.detach().cpu().numpy()\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        for cls, pred in enumerate(preds):\n",
    "            pred, num = post_process(pred, best_threshold, min_size)\n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{cls+1}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "# save predictions to submission.csv\n",
    "df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>004f40c73.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>004f40c73.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>004f40c73.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>004f40c73.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>006f39c41.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>006f39c41.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>006f39c41.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>006f39c41.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>00b7fb703.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>00b7fb703.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>00b7fb703.jpg_3</td>\n",
       "      <td>44647 33 44900 39 45154 45 45408 49 45661 54 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>00b7fb703.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>00bbcd9af.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>00bbcd9af.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>00bbcd9af.jpg_3</td>\n",
       "      <td>154551 16 154793 46 155038 71 155276 100 15552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>00bbcd9af.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0108ce457.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0108ce457.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0108ce457.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0108ce457.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0109b68ec.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0109b68ec.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0109b68ec.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0109b68ec.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>010ec96b4.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>010ec96b4.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>010ec96b4.jpg_3</td>\n",
       "      <td>34255 21 34505 33 34759 39 35012 46 35266 50 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>010ec96b4.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>015be539e.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>015be539e.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>015be539e.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>015be539e.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>017bd7ce3.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>017bd7ce3.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>017bd7ce3.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>017bd7ce3.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>01b47d973.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>01b47d973.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>01b47d973.jpg_3</td>\n",
       "      <td>133585 19 133830 42 134081 50 134333 56 134586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>01b47d973.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>01d49cd47.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>01d49cd47.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>01d49cd47.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>01d49cd47.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>020ffb2d3.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>020ffb2d3.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>020ffb2d3.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>020ffb2d3.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0241cf678.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0241cf678.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ImageId_ClassId                                      EncodedPixels\n",
       "0   004f40c73.jpg_1                                                   \n",
       "1   004f40c73.jpg_2                                                   \n",
       "2   004f40c73.jpg_3                                                   \n",
       "3   004f40c73.jpg_4                                                   \n",
       "4   006f39c41.jpg_1                                                   \n",
       "5   006f39c41.jpg_2                                                   \n",
       "6   006f39c41.jpg_3                                                   \n",
       "7   006f39c41.jpg_4                                                   \n",
       "8   00b7fb703.jpg_1                                                   \n",
       "9   00b7fb703.jpg_2                                                   \n",
       "10  00b7fb703.jpg_3  44647 33 44900 39 45154 45 45408 49 45661 54 4...\n",
       "11  00b7fb703.jpg_4                                                   \n",
       "12  00bbcd9af.jpg_1                                                   \n",
       "13  00bbcd9af.jpg_2                                                   \n",
       "14  00bbcd9af.jpg_3  154551 16 154793 46 155038 71 155276 100 15552...\n",
       "15  00bbcd9af.jpg_4                                                   \n",
       "16  0108ce457.jpg_1                                                   \n",
       "17  0108ce457.jpg_2                                                   \n",
       "18  0108ce457.jpg_3                                                   \n",
       "19  0108ce457.jpg_4                                                   \n",
       "20  0109b68ec.jpg_1                                                   \n",
       "21  0109b68ec.jpg_2                                                   \n",
       "22  0109b68ec.jpg_3                                                   \n",
       "23  0109b68ec.jpg_4                                                   \n",
       "24  010ec96b4.jpg_1                                                   \n",
       "25  010ec96b4.jpg_2                                                   \n",
       "26  010ec96b4.jpg_3  34255 21 34505 33 34759 39 35012 46 35266 50 3...\n",
       "27  010ec96b4.jpg_4                                                   \n",
       "28  015be539e.jpg_1                                                   \n",
       "29  015be539e.jpg_2                                                   \n",
       "30  015be539e.jpg_3                                                   \n",
       "31  015be539e.jpg_4                                                   \n",
       "32  017bd7ce3.jpg_1                                                   \n",
       "33  017bd7ce3.jpg_2                                                   \n",
       "34  017bd7ce3.jpg_3                                                   \n",
       "35  017bd7ce3.jpg_4                                                   \n",
       "36  01b47d973.jpg_1                                                   \n",
       "37  01b47d973.jpg_2                                                   \n",
       "38  01b47d973.jpg_3  133585 19 133830 42 134081 50 134333 56 134586...\n",
       "39  01b47d973.jpg_4                                                   \n",
       "40  01d49cd47.jpg_1                                                   \n",
       "41  01d49cd47.jpg_2                                                   \n",
       "42  01d49cd47.jpg_3                                                   \n",
       "43  01d49cd47.jpg_4                                                   \n",
       "44  020ffb2d3.jpg_1                                                   \n",
       "45  020ffb2d3.jpg_2                                                   \n",
       "46  020ffb2d3.jpg_3                                                   \n",
       "47  020ffb2d3.jpg_4                                                   \n",
       "48  0241cf678.jpg_1                                                   \n",
       "49  0241cf678.jpg_2                                                   "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
